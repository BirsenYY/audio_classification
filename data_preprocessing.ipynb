{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b6b686-626d-427f-90ca-d8cf64f7c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 901/873 files in fold 1\n",
      "Processed 1001/873 files in fold 1\n",
      "Processed 1401/873 files in fold 1\n",
      "Processed 1501/873 files in fold 1\n",
      "Processed 2501/873 files in fold 1\n",
      "Processed 2801/873 files in fold 1\n",
      "Processed 4901/873 files in fold 1\n",
      "Processed 5101/873 files in fold 1\n",
      "Processed 6901/873 files in fold 1\n",
      "Processed 7401/873 files in fold 1\n",
      "Processed 8401/873 files in fold 1\n",
      "Processed 8601/873 files in fold 1\n",
      "Processed 301/888 files in fold 2\n",
      "Processed 2001/888 files in fold 2\n",
      "Processed 2701/888 files in fold 2\n",
      "Processed 4801/888 files in fold 2\n",
      "Processed 5201/888 files in fold 2\n",
      "Processed 7001/888 files in fold 2\n",
      "Processed 7601/888 files in fold 2\n",
      "Processed 8001/888 files in fold 2\n",
      "Processed 201/925 files in fold 3\n",
      "Processed 501/925 files in fold 3\n",
      "Processed 1901/925 files in fold 3\n",
      "Processed 3101/925 files in fold 3\n",
      "Processed 4701/925 files in fold 3\n",
      "Processed 5601/925 files in fold 3\n",
      "Processed 6001/925 files in fold 3\n",
      "Processed 8101/925 files in fold 3\n",
      "Processed 101/990 files in fold 4\n",
      "Processed 601/990 files in fold 4\n",
      "Processed 1701/990 files in fold 4\n",
      "Processed 2101/990 files in fold 4\n",
      "Processed 3201/990 files in fold 4\n",
      "Processed 3401/990 files in fold 4\n",
      "Processed 5001/990 files in fold 4\n",
      "Processed 5701/990 files in fold 4\n",
      "Processed 5801/990 files in fold 4\n",
      "Processed 6201/990 files in fold 4\n",
      "Processed 6401/990 files in fold 4\n",
      "Processed 8301/990 files in fold 4\n",
      "Processed 1/936 files in fold 5\n",
      "Processed 1601/936 files in fold 5\n",
      "Processed 2401/936 files in fold 5\n",
      "Processed 3501/936 files in fold 5\n",
      "Processed 4001/936 files in fold 5\n",
      "Processed 4101/936 files in fold 5\n",
      "Processed 4201/936 files in fold 5\n",
      "Processed 5301/936 files in fold 5\n",
      "Processed 7501/936 files in fold 5\n",
      "Processed 1301/823 files in fold 6\n",
      "Processed 3001/823 files in fold 6\n",
      "Processed 4501/823 files in fold 6\n",
      "Processed 5401/823 files in fold 6\n",
      "Processed 6301/823 files in fold 6\n",
      "Processed 6501/823 files in fold 6\n",
      "Processed 7201/823 files in fold 6\n",
      "Processed 8501/823 files in fold 6\n",
      "Processed 801/838 files in fold 7\n",
      "Processed 2301/838 files in fold 7\n",
      "Processed 3801/838 files in fold 7\n",
      "Processed 4401/838 files in fold 7\n",
      "Processed 4601/838 files in fold 7\n",
      "Processed 7301/838 files in fold 7\n",
      "Processed 8201/838 files in fold 7\n",
      "Processed 701/806 files in fold 8\n",
      "Processed 1101/806 files in fold 8\n",
      "Processed 2601/806 files in fold 8\n",
      "Processed 3601/806 files in fold 8\n",
      "Processed 3901/806 files in fold 8\n",
      "Processed 6101/806 files in fold 8\n",
      "Processed 6701/806 files in fold 8\n",
      "Processed 6801/806 files in fold 8\n",
      "Processed 7701/806 files in fold 8\n",
      "Processed 7801/806 files in fold 8\n",
      "Processed 7901/806 files in fold 8\n",
      "Processed 401/816 files in fold 9\n",
      "Processed 1801/816 files in fold 9\n",
      "Processed 2201/816 files in fold 9\n",
      "Processed 3701/816 files in fold 9\n",
      "Processed 4301/816 files in fold 9\n",
      "Processed 5901/816 files in fold 9\n",
      "Processed 6601/816 files in fold 9\n",
      "Processed 7101/816 files in fold 9\n",
      "Processed 1201/837 files in fold 10\n",
      "Processed 2901/837 files in fold 10\n",
      "Processed 3301/837 files in fold 10\n",
      "Processed 5501/837 files in fold 10\n",
      "Processed 8701/837 files in fold 10\n",
      "Data preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as transforms\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "\n",
    "# Define augmentations using audiomentations library\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),  # Add Gaussian noise\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),  # Stretch or compress time\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),  # Shift pitch\n",
    "])\n",
    "\n",
    "# Define paths for data and output\n",
    "data_path = 'UrbanSound8K/audio'\n",
    "metadata_path = 'UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "output_path = 'preprocessed_data'\n",
    "fixed_size = (64, 512)  # Fixed size for spectrograms\n",
    "\n",
    "# Create output directories for each fold if they don't exist\n",
    "for fold in range(1, 11):\n",
    "    fold_path = os.path.join(output_path, f'fold{fold}')\n",
    "    os.makedirs(fold_path, exist_ok=True)\n",
    "\n",
    "# Load metadata from the UrbanSound8K dataset\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "def preprocess_audio(file_path, n_mels=64, n_fft=2048, hop_length=512, augmentations=None):\n",
    "    \"\"\"\n",
    "    Preprocess an audio file to create a mel spectrogram.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the audio file.\n",
    "    - n_mels (int): Number of mel bands to generate.\n",
    "    - n_fft (int): FFT window size.\n",
    "    - hop_length (int): Number of samples between successive frames.\n",
    "    - augmentations (Compose): Augmentations to apply to the waveform.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Mel spectrogram in dB.\n",
    "    \"\"\"\n",
    "    waveform, sample_rate = torchaudio.load(file_path, normalize=True)\n",
    "    \n",
    "    # Convert to mono if the audio is stereo\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Apply augmentations if provided\n",
    "    if augmentations:\n",
    "        waveform = torch.tensor(augmentations(samples=waveform.numpy()[0], sample_rate=sample_rate)).unsqueeze(0)\n",
    "    \n",
    "    # Create mel spectrogram\n",
    "    mel_spectrogram_transform = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "    mel_spectrogram = mel_spectrogram_transform(waveform)\n",
    "    \n",
    "    # Convert to decibel scale\n",
    "    mel_spectrogram_db_transform = T.AmplitudeToDB()\n",
    "    mel_spectrogram_db = mel_spectrogram_db_transform(mel_spectrogram)\n",
    "    \n",
    "    return mel_spectrogram_db.squeeze().numpy()\n",
    "\n",
    "def pad_spectrogram(spectrogram, size=fixed_size):\n",
    "    \"\"\"\n",
    "    Pad the spectrogram to a fixed size.\n",
    "\n",
    "    Args:\n",
    "    - spectrogram (np.array): Input spectrogram.\n",
    "    - size (tuple): Target size (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Padded or trimmed spectrogram.\n",
    "    \"\"\"\n",
    "    # Ensure the spectrogram is 2D\n",
    "    if spectrogram.ndim == 3:\n",
    "        spectrogram = spectrogram[0]  # Remove the channel dimension if present\n",
    "\n",
    "    if spectrogram.ndim != 2:\n",
    "        raise ValueError(f\"Expected a 2D spectrogram, but got {spectrogram.ndim}D array\")\n",
    "\n",
    "    target_height, target_width = size\n",
    "    height, width = spectrogram.shape\n",
    "\n",
    "    # Pad or trim width\n",
    "    if width < target_width:\n",
    "        pad_width = target_width - width\n",
    "        spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        spectrogram = spectrogram[:, :target_width]\n",
    "\n",
    "    # Pad or trim height\n",
    "    if height < target_height:\n",
    "        pad_height = target_height - height\n",
    "        spectrogram = np.pad(spectrogram, ((0, pad_height), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        spectrogram = spectrogram[:target_height, :]\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def spectrogram_to_tensor(spectrogram):\n",
    "    \"\"\"\n",
    "    Convert a mel spectrogram to a tensor.\n",
    "\n",
    "    Args:\n",
    "    - spectrogram (np.array): Input spectrogram.\n",
    "\n",
    "    Returns:\n",
    "    - Tensor: Spectrogram as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    tensor = transform(spectrogram)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def process_and_save_data(metadata, data_path, output_path, augmentations, spectrogram_file_name, augmented_spectrogram_file_name):\n",
    "    \"\"\"\n",
    "    Process and save audio files as mel spectrogram tensors.\n",
    "\n",
    "    Args:\n",
    "    - metadata (DataFrame): Metadata for the dataset.\n",
    "    - data_path (str): Path to the audio files.\n",
    "    - output_path (str): Path to save the processed data.\n",
    "    - augmentations (Compose): Augmentations to apply.\n",
    "    - spectrogram_file_name (str): Filename for non-augmented spectrograms.\n",
    "    - augmented_spectrogram_file_name (str): Filename for augmented spectrograms.\n",
    "    \"\"\"\n",
    "    for fold in range(1, 11):\n",
    "        spectrograms = []\n",
    "        labels = []\n",
    "        augmented_spectrograms = []\n",
    "        \n",
    "        fold_metadata = metadata[metadata['fold'] == fold]\n",
    "        for index, row in fold_metadata.iterrows():\n",
    "            file_name = row['slice_file_name']\n",
    "            file_path = os.path.join(data_path, f'fold{fold}', file_name)\n",
    "            \n",
    "            # Process audio file without augmentation\n",
    "            spectrogram = preprocess_audio(file_path, augmentations=None)\n",
    "            spectrogram = pad_spectrogram(spectrogram)\n",
    "            tensor = spectrogram_to_tensor(spectrogram)\n",
    "            \n",
    "            # Append tensor and label to lists\n",
    "            spectrograms.append(tensor)\n",
    "\n",
    "            # Process audio file with augmentation\n",
    "            augmented_spectrogram = preprocess_audio(file_path, augmentations=augmentations)\n",
    "            augmented_spectrogram = pad_spectrogram(augmented_spectrogram)\n",
    "            augmented_tensor = spectrogram_to_tensor(augmented_spectrogram)\n",
    "            \n",
    "            # Append augmented tensor and label to lists\n",
    "            augmented_spectrograms.append(augmented_tensor)\n",
    "\n",
    "            labels.append(row['classID'])\n",
    "            \n",
    "            if index % 100 == 0:\n",
    "                print(f'Processed {index + 1}/{len(fold_metadata)} files in fold {fold}')\n",
    "        \n",
    "        # Save lists as .pt files\n",
    "        torch.save(spectrograms, os.path.join(output_path, f'fold{fold}', spectrogram_file_name))\n",
    "        torch.save(labels, os.path.join(output_path, f'fold{fold}', 'labels.pt'))\n",
    "        torch.save(augmented_spectrograms, os.path.join(output_path, f'fold{fold}', augmented_spectrogram_file_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define filenames for saving the spectrograms\n",
    "    spectrogram_file_name = 'spectrograms.pt'\n",
    "    augmented_spectrogram_file_name = 'spectrograms_augmented.pt'\n",
    "    \n",
    "    # Process and save the data\n",
    "    process_and_save_data(metadata, data_path, output_path, augment, spectrogram_file_name, augmented_spectrogram_file_name)\n",
    "    print('Data preprocessing completed successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7edf0-7992-4aca-9515-0d316870e73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
