{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65426158-1d5e-4f28-96eb-7922f8dd0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbirsenyildiz2018\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/birsen/Desktop/classify_audio/wandb/run-20240620_111351-sa4o78ft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/birsenyildiz2018/audio_classification/runs/sa4o78ft' target=\"_blank\">giddy-smoke-186</a></strong> to <a href='https://wandb.ai/birsenyildiz2018/audio_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/birsenyildiz2018/audio_classification' target=\"_blank\">https://wandb.ai/birsenyildiz2018/audio_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/birsenyildiz2018/audio_classification/runs/sa4o78ft' target=\"_blank\">https://wandb.ai/birsenyildiz2018/audio_classification/runs/sa4o78ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch [1/100], Train Loss: 1.666759069798056, Train Accuracy: 0.41519277261738136, Val Loss: 1.3778908740204225, Val Accuracy: 0.4868270332187858\n",
      "Epoch [2/100], Train Loss: 1.2755824180486048, Train Accuracy: 0.5645756457564576, Val Loss: 1.4935795172519837, Val Accuracy: 0.5280641466208477\n",
      "Epoch [3/100], Train Loss: 1.0943932516578803, Train Accuracy: 0.6401577808881537, Val Loss: 1.1748976725210165, Val Accuracy: 0.6323024054982818\n",
      "Epoch [4/100], Train Loss: 0.9841582248389592, Train Accuracy: 0.6742588115536328, Val Loss: 1.203285648377627, Val Accuracy: 0.6071019473081328\n",
      "Epoch [5/100], Train Loss: 0.8980165245742618, Train Accuracy: 0.7056877465326378, Val Loss: 1.1630357827517586, Val Accuracy: 0.6357388316151202\n",
      "Epoch [6/100], Train Loss: 0.8193597041221198, Train Accuracy: 0.7278279679348517, Val Loss: 1.3027903292187302, Val Accuracy: 0.6575028636884307\n",
      "Epoch [7/100], Train Loss: 0.7754920651734004, Train Accuracy: 0.7418246596259066, Val Loss: 1.7280701001485188, Val Accuracy: 0.5922107674684994\n",
      "Epoch [8/100], Train Loss: 0.7286600587340405, Train Accuracy: 0.7615472706451203, Val Loss: 0.9906243853962299, Val Accuracy: 0.7479954180985109\n",
      "Epoch [9/100], Train Loss: 0.695976636696141, Train Accuracy: 0.7733808372566484, Val Loss: 1.3807143553289214, Val Accuracy: 0.5624284077892325\n",
      "Epoch [10/100], Train Loss: 0.635657895785401, Train Accuracy: 0.7981931543453366, Val Loss: 1.7609048248839405, Val Accuracy: 0.5979381443298969\n",
      "Epoch [11/100], Train Loss: 0.6290477468685607, Train Accuracy: 0.7873775289477033, Val Loss: 1.2943255194683665, Val Accuracy: 0.6964490263459335\n",
      "Epoch [12/100], Train Loss: 0.5967637574207025, Train Accuracy: 0.8045552869321797, Val Loss: 1.4153039365972713, Val Accuracy: 0.6769759450171822\n",
      "Epoch [13/100], Train Loss: 0.507050760629781, Train Accuracy: 0.8368749204733427, Val Loss: 1.0234669778082106, Val Accuracy: 0.7617411225658648\n",
      "Epoch [14/100], Train Loss: 0.45881302468360174, Train Accuracy: 0.8527802519404505, Val Loss: 1.0743894852860003, Val Accuracy: 0.7605956471935853\n",
      "Epoch [15/100], Train Loss: 0.43937228898963243, Train Accuracy: 0.859651355134241, Val Loss: 1.070025121428303, Val Accuracy: 0.7422680412371134\n",
      "Epoch [16/100], Train Loss: 0.42229861273597497, Train Accuracy: 0.8702124952284006, Val Loss: 1.0914796454936504, Val Accuracy: 0.7697594501718213\n",
      "Epoch [17/100], Train Loss: 0.41575112602140085, Train Accuracy: 0.871612164397506, Val Loss: 1.0967118178173165, Val Accuracy: 0.7663230240549829\n",
      "Epoch [18/100], Train Loss: 0.4146011395374924, Train Accuracy: 0.8691945540145056, Val Loss: 1.0999887698977537, Val Accuracy: 0.7628865979381443\n",
      "Epoch [19/100], Train Loss: 0.4108447737784191, Train Accuracy: 0.8732663188700852, Val Loss: 1.092110412636983, Val Accuracy: 0.7697594501718213\n",
      "Epoch [20/100], Train Loss: 0.4017457553396578, Train Accuracy: 0.8745387453874539, Val Loss: 1.1259292022059464, Val Accuracy: 0.7594501718213058\n",
      "Epoch [21/100], Train Loss: 0.3982688160566963, Train Accuracy: 0.8814098485812444, Val Loss: 1.1261821078544083, Val Accuracy: 0.7571592210767468\n",
      "Epoch [22/100], Train Loss: 0.40089278729882066, Train Accuracy: 0.8753022012978751, Val Loss: 1.1440246906750253, Val Accuracy: 0.7537227949599083\n",
      "Epoch [23/100], Train Loss: 0.3960652574583962, Train Accuracy: 0.8807736353225601, Val Loss: 1.113414654275669, Val Accuracy: 0.7605956471935853\n",
      "Epoch [24/100], Train Loss: 0.40183780175202494, Train Accuracy: 0.8754294439496119, Val Loss: 1.1191554469614367, Val Accuracy: 0.7594501718213058\n",
      "Epoch [25/100], Train Loss: 0.4037008701632505, Train Accuracy: 0.8753022012978751, Val Loss: 1.1275506018226773, Val Accuracy: 0.7583046964490263\n",
      "Epoch [26/100], Train Loss: 0.3977071808781207, Train Accuracy: 0.8791194808499809, Val Loss: 1.1114099322725408, Val Accuracy: 0.7651775486827033\n",
      "Epoch [27/100], Train Loss: 0.4041419286834995, Train Accuracy: 0.8774653263774017, Val Loss: 1.1395749637487964, Val Accuracy: 0.7651775486827033\n",
      "Epoch [28/100], Train Loss: 0.3995032687081925, Train Accuracy: 0.8763201425117699, Val Loss: 1.1062489467388166, Val Accuracy: 0.7651775486827033\n",
      "Epoch [29/100], Train Loss: 0.40108848553999854, Train Accuracy: 0.8749204733426644, Val Loss: 1.1236184555503783, Val Accuracy: 0.7571592210767468\n",
      "Epoch [30/100], Train Loss: 0.4013570839666443, Train Accuracy: 0.8767018704669806, Val Loss: 1.134990386673402, Val Accuracy: 0.7560137457044673\n",
      "Epoch [31/100], Train Loss: 0.4070788709121376, Train Accuracy: 0.8747932306909276, Val Loss: 1.1285638298502219, Val Accuracy: 0.7686139747995419\n",
      "Epoch [32/100], Train Loss: 0.40063965457482925, Train Accuracy: 0.8783560249395598, Val Loss: 1.1215887411080412, Val Accuracy: 0.7537227949599083\n",
      "Epoch [33/100], Train Loss: 0.39866906623680154, Train Accuracy: 0.8728845909148747, Val Loss: 1.1095116008734511, Val Accuracy: 0.7628865979381443\n",
      "Epoch [34/100], Train Loss: 0.40018114193142, Train Accuracy: 0.8740297747805065, Val Loss: 1.1279262046224063, Val Accuracy: 0.7583046964490263\n",
      "Epoch [35/100], Train Loss: 0.4044163515282915, Train Accuracy: 0.8746659880391907, Val Loss: 1.1498175165087907, Val Accuracy: 0.7548682703321878\n",
      "Epoch [36/100], Train Loss: 0.3988498031054005, Train Accuracy: 0.8755566866013488, Val Loss: 1.1045622185196937, Val Accuracy: 0.7640320733104238\n",
      "Epoch [37/100], Train Loss: 0.4045555029362573, Train Accuracy: 0.8745387453874539, Val Loss: 1.1217807225481888, Val Accuracy: 0.7617411225658648\n",
      "Epoch [38/100], Train Loss: 0.4107375293192722, Train Accuracy: 0.872630105611401, Val Loss: 1.1421055678376355, Val Accuracy: 0.7560137457044673\n",
      "Epoch [39/100], Train Loss: 0.3998369220741409, Train Accuracy: 0.8750477159944013, Val Loss: 1.124450018384066, Val Accuracy: 0.7594501718213058\n",
      "Epoch [40/100], Train Loss: 0.40076315359375164, Train Accuracy: 0.8791194808499809, Val Loss: 1.116829136324639, Val Accuracy: 0.7594501718213058\n",
      "Epoch [41/100], Train Loss: 0.4041819326643089, Train Accuracy: 0.8754294439496119, Val Loss: 1.134186556453967, Val Accuracy: 0.7605956471935853\n",
      "Epoch [42/100], Train Loss: 0.4077161269563196, Train Accuracy: 0.8732663188700852, Val Loss: 1.121573385162725, Val Accuracy: 0.7617411225658648\n",
      "Epoch [43/100], Train Loss: 0.40401322216474306, Train Accuracy: 0.8722483776561903, Val Loss: 1.1316510539284277, Val Accuracy: 0.7571592210767468\n",
      "Epoch [44/100], Train Loss: 0.406342218859321, Train Accuracy: 0.8746659880391907, Val Loss: 1.1263616410044597, Val Accuracy: 0.7583046964490263\n",
      "Epoch [45/100], Train Loss: 0.4022547845728814, Train Accuracy: 0.8765746278152436, Val Loss: 1.1064738244125523, Val Accuracy: 0.7605956471935853\n",
      "Epoch [46/100], Train Loss: 0.4035553621842306, Train Accuracy: 0.8742842600839802, Val Loss: 1.12758097008195, Val Accuracy: 0.7560137457044673\n",
      "Epoch [47/100], Train Loss: 0.40085127836330076, Train Accuracy: 0.8745387453874539, Val Loss: 1.1042668564759306, Val Accuracy: 0.7628865979381443\n",
      "Epoch [48/100], Train Loss: 0.4048756323048504, Train Accuracy: 0.8770835984221911, Val Loss: 1.122556428933881, Val Accuracy: 0.7628865979381443\n",
      "Epoch [49/100], Train Loss: 0.4049831481323638, Train Accuracy: 0.8756839292530856, Val Loss: 1.1186847404106377, Val Accuracy: 0.7560137457044673\n",
      "Epoch [50/100], Train Loss: 0.4021076782921644, Train Accuracy: 0.8746659880391907, Val Loss: 1.119293838363879, Val Accuracy: 0.7640320733104238\n",
      "Epoch [51/100], Train Loss: 0.4025282405884701, Train Accuracy: 0.8732663188700852, Val Loss: 1.113784610474096, Val Accuracy: 0.7686139747995419\n",
      "Epoch [52/100], Train Loss: 0.40349269412312894, Train Accuracy: 0.8761928998600331, Val Loss: 1.1333615635132326, Val Accuracy: 0.7617411225658648\n",
      "Epoch [53/100], Train Loss: 0.4026306475228155, Train Accuracy: 0.8747932306909276, Val Loss: 1.1362169721555329, Val Accuracy: 0.7548682703321878\n",
      "Epoch [54/100], Train Loss: 0.3972049784358486, Train Accuracy: 0.8751749586461381, Val Loss: 1.1337782611551972, Val Accuracy: 0.7571592210767468\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 154\u001b[0m\n\u001b[1;32m    151\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    152\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     57\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 60\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     62\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     64\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" train.py\n",
    "This training process does not include hyper-parameter tuning. \n",
    "Instead, after finding best hyper parameters by running train_with_optuna.py, the hyper-parameters can be used here to \n",
    "train the model for more epochs. \"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from advanced_model import AdvancedAudioClassifier\n",
    "import wandb\n",
    "\n",
    "# Directory where the preprocessed data is stored\n",
    "data_dir = 'preprocessed_data'\n",
    "\n",
    "def load_data_for_fold(fold, train=True):\n",
    "    \"\"\"\n",
    "    Load spectrograms and labels for a specific fold.\n",
    "\n",
    "    Args:\n",
    "    - fold (int): The fold number to load.\n",
    "    - train (bool): Whether to load the training or validation set. Default is True (training set).\n",
    "\n",
    "    Returns:\n",
    "    - spectrograms (Tensor): Loaded spectrograms.\n",
    "    - labels (Tensor): Corresponding labels.\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        spectrograms = torch.load(os.path.join(f'{data_dir}/fold{fold}', 'spectrograms_augmented.pt'))\n",
    "    else:\n",
    "        spectrograms = torch.load(os.path.join(f'{data_dir}/fold{fold}', 'spectrograms.pt'))\n",
    "    \n",
    "    labels = torch.tensor(torch.load(os.path.join(f'{data_dir}/fold{fold}', 'labels.pt')), dtype=torch.long)\n",
    "    return spectrograms, labels\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set.\n",
    "\n",
    "    Args:\n",
    "    - model (nn.Module): The model to evaluate.\n",
    "    - val_loader (DataLoader): DataLoader for the validation set.\n",
    "    - criterion (Loss): The loss function.\n",
    "\n",
    "    Returns:\n",
    "    - val_loss (float): Average loss on the validation set.\n",
    "    - val_accuracy (float): Accuracy on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            \n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)  # Get the index of the max log-probability\n",
    "            total += labels.size(0)  # Update the total number of samples\n",
    "            correct += predicted.eq(labels).sum().item()  # Update the number of correct predictions\n",
    "\n",
    "    val_loss = running_loss / total  # Compute average loss over all samples\n",
    "    val_accuracy = correct / total  # Compute accuracy\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def train_model(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    Train the model and evaluate it on the validation set at each epoch.\n",
    "\n",
    "    Args:\n",
    "    - train_loader (DataLoader): DataLoader for the training set.\n",
    "    - val_loader (DataLoader): DataLoader for the validation set.\n",
    "    - num_epochs (int): Number of epochs to train.\n",
    "    - model (nn.Module): The model to train.\n",
    "    - criterion (Loss): The loss function.\n",
    "    - optimizer (Optimizer): The optimizer.\n",
    "    - scheduler (LRScheduler): Learning rate scheduler.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            \n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            \n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)  # Get the index of the max log-probability\n",
    "            \n",
    "            total += labels.size(0)  # Update the total number of samples\n",
    "            correct += predicted.eq(labels).sum().item()  # Update the number of correct predictions\n",
    "\n",
    "        train_loss = running_loss / total  # Compute average loss over all samples\n",
    "        train_accuracy = correct / total  # Compute accuracy\n",
    "\n",
    "        # Log training progress to wandb\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "        })\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        # Log validation progress to wandb\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        })\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}')\n",
    "\n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize wandb for logging\n",
    "    wandb.init(project=\"audio_classification\", entity=\"username\")\n",
    "\n",
    "    # Determine the device to use (MPS, CUDA, or CPU)\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    lr = 9e-4  # Learning rate\n",
    "    weight_decay = 1e-5  # Weight decay for regularization\n",
    "    dropout_rate = 0.47  # Dropout rate to prevent overfitting\n",
    "    batch_size = 64  # Batch size for training\n",
    "    \n",
    "    num_epochs = 100  # Number of epochs to train\n",
    "    \n",
    "    for fold in range(1, 11):\n",
    "        X_val, y_val = load_data_for_fold(fold, train=False)  # Load validation data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in range(1, 11):\n",
    "            if train_fold == fold:\n",
    "                continue\n",
    "            X_fold, y_fold = load_data_for_fold(train_fold, train=True)  # Load training data\n",
    "            X_train.extend(X_fold)\n",
    "            y_train.extend(y_fold)\n",
    "\n",
    "        X_train = torch.stack(X_train)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        \n",
    "        # Create datasets and data loaders\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(torch.stack(X_val), y_val)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize the model, loss function, optimizer, and learning rate scheduler\n",
    "        model = AdvancedAudioClassifier(dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cc197-e750-4170-ab43-870dbcda6840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
